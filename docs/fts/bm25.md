# BM25 

## What is BM25?

**BM25** (Best Matching 25th Iteration) an advancement on TF-IDF

**Why is it better than TF-IDF?**

- It has **diminishing returns** - Adding the 10th query term doesn't help as much as adding the 2nd "caquery term".
- It considers **document length** - Longer docs aren't automatically penalized. 
- It has **tuning knobs** - You can adjust it for different use cases with `k1` for key word saturation and `b` for document length.

## The BM25 Formula

A helpful infographic:

![bm25](../images/bm25.png)

## The Formula Breakdown

```
BM25(D, Q) = Σ IDF(qi) × (f(qi, D) × (k1 + 1)) / (f(qi, D) + k1 × (1 - b + b × |D| / avgdl))

Where:

- D = Document being scored
- Q = Query (search terms)
- qi = Each term in the query
- f(qi, D) = Frequency of term qi in document D
- |D| = Length of document D (word count)
- avgdl = Average document length in collection
- k1 = Term frequency saturation parameter (usually 1.2 to 2.0)
- b = Length normalization parameter (usually 0.75)
```

BM25 is a ranking formula that scores how well a document matches a search query.

**The core idea:** For each word in your query, BM25 calculates a score based on:

1. **IDF (Inverse Document Frequency)** - How rare/important the word is across all documents. Rare words get higher scores.

2. **Term frequency with diminishing returns** - How often the word appears in this document, but with a ceiling. The formula `(f × (k1 + 1)) / (f + k1)` means the 1st occurrence matters a lot, the 10th occurrence barely matters.

3. **Length normalization** - Longer documents get penalized (controlled by `b`), because they naturally contain more words. The `(1 - b + b × |D| / avgdl)` part adjusts for document length.

**Example:** Searching "php tutorial"

- "php" appears in 1000 docs → low IDF
- "tutorial" appears in 100 docs → higher IDF  
- A short doc with "tutorial" mentioned 3 times scores higher than a long doc with it mentioned 20 times

The final score is the sum of scores for each query term. Documents with the highest BM25 scores are ranked first.

**Remember:**

- IDF: How special is this word?
- Numerator: Boost the frequency (but not too much)
- Denominator: Normalize for document length and saturation
- Result: A score that balances everything perfectly!

## Understanding the Parameters

### k1 (Term Frequency Saturation)

![idf](../images/fts/k1.png)

This slide explains how the **k₁ parameter** controls **term frequency saturation** in the BM25 ranking algorithm.

### What the diagram shows

The graph compares two approaches to scoring documents based on how many times a search term appears:

**Standard TF-IDF (blue line):** Score increases linearly forever. If a term appears 100 times, the score is roughly twice as high as if it appears 50 times. There's no upper limit.

**BM25 with k₁ saturation (orange curve):** Score increases quickly at first, then flattens out. After a certain point, additional mentions of the term barely increase the score.

### What k₁ does

The **k₁ parameter** controls how quickly the curve flattens:

- **Lower k₁** → curve flattens sooner (more aggressive saturation)
- **Higher k₁** → curve stays steeper longer (less saturation, closer to linear)

### Why this matters - "Eliteness"

The image explains the key insight: once a term appears several times in a document, that document is already "elite" (highly relevant) for that topic. Seeing the term 50 more times doesn't make it 50 times more relevant—it just confirms what you already know.

For example, if you search for "php" and a document mentions it 5 times versus 500 times in another, the second document isn't necessarily 100x better. BM25's saturation prevents over-rewarding documents that spam keywords.

**Default: 1.2-2.0**

Controls how quickly we stop caring about additional word occurrences.

```
Word "php" appears:

- 1 time: Very important! ⭐⭐⭐⭐⭐
- 2 times: More important! ⭐⭐⭐⭐⭐⭐
- 5 times: Somewhat more important ⭐⭐⭐⭐⭐⭐⭐
- 50 times: Not much more important (saturated) ⭐⭐⭐⭐⭐⭐⭐⭐
```

**Higher k1** = More weight to term frequency 

**Lower k1** = Less weight to term frequency - dampens the effect of kew word stuffing so after a certain number it has less effect on the BM25 score.

To reduce the impact of  **keyword stuffing**, you want a **lower k1**.

Here's why:

**Lower k1 (e.g., 0.5-1.0)**: Term frequency saturates quickly
- After a keyword appears a few times, additional repetitions barely increase the score
- Makes stuffing less effective
- Better for fighting spam/manipulation

**Higher k1 (e.g., 1.5-2.0)**: Term frequency keeps mattering more
- Repeated keywords continue boosting the score significantly
- Rewards documents that mention terms many times
- Can be exploited by keyword stuffing

**The math intuition:**

BM25's term frequency component looks like:
```
(tf * (k1 + 1)) / (tf + k1)
```

Let's see what happens with keyword "python" appearing different times:

**With k1 = 2.0 (higher):**
- 1 occurrence: 0.33
- 5 occurrences: 0.83
- 10 occurrences: 0.92
- 20 occurrences: 0.95

**With k1 = 0.5 (lower):**
- 1 occurrence: 0.75
- 5 occurrences: 0.91
- 10 occurrences: 0.95
- 20 occurrences: 0.98

Notice how with lower k1, going from 1→20 occurrences only increases the score from 0.75→0.98, while higher k1 shows more dramatic gains (0.33→0.95).

**Recommendation:** Use **k1 = 1.2** (the common default) or lower if you're dealing with keyword stuffing. Values around **k1 = 0.5-1.0** are very aggressive at diminishing returns from repetition.

### b (Length Normalization)

![idf](../images/fts/b.png)

![idf](../images/fts/length-normalisation.png)

**Default: 0.75**

Controls how much document length affects the score.

```
b = 0: Document length doesn't matter at all
b = 0.5: Document length matters somewhat
b = 0.75: Document length matters a good amount (default)
b = 1.0: Document length matters completely
```

### Can b>1?

Yes, `b` in BM25 can technically be greater than 1, though it's unusual and not recommended in practice.

The parameter `b` controls document length normalization in BM25:
- `b = 0`: no length normalization (document length is ignored)
- `b = 1`: full linear normalization (standard setting)
- `b > 1`: over-normalization (penalizes longer documents more heavily)

**What happens when b > 1:**

When `b > 1`, you're applying a stronger penalty to longer documents than the standard normalization. The length normalization term becomes:

```
1 - b + b * (doc_length / avg_doc_length)
```

For a document longer than average (doc_length > avg_doc_length), values of `b > 1` will make this denominator larger, further reducing the score.

**Why it's not standard:**

The typical range is `b ∈ [0, 1]` because:

- BM25 was empirically tuned with `b ≈ 0.75` as optimal for most collections
- Values > 1 can over-penalize longer documents that are legitimately relevant
- The theoretical justification for BM25's length normalization assumes `b ≤ 1`

**When you might consider b > 1:**

- Your collection has verbose/padded documents that aren't proportionally more informative
- You want to strongly favor concise, focused documents
- You're dealing with spam or artificially inflated content

If you're experimenting with this, I'd suggest testing values like 1.1 or 1.2 first and evaluating against your specific use case, rather than jumping to much higher values.

**Higher b** = Longer docs penalized more  

**Lower b** = Longer docs penalized less

## Tuning Parameters for Different Use Cases

### *Unfortunately, MySQL does not enable k1 and b tuning for our WordPress sites. If it did then...*

### Higher k1 (e.g., k1 = 2.0):

**Use when:**

- Longer documents are common
- Term frequency is very important
- E-commerce product descriptions
- Technical documentation

**Effect:** More emphasis on how often terms appear

### Lower k1 (e.g., k1 = 1.0):

**Use when:**

- Short documents (tweets, titles)
- Presence matters more than frequency
- News headlines

**Effect:** Less emphasis on repetition

### Higher b (e.g., b = 1.0):

**Use when:**

- Document lengths vary widely
- Shorter docs should be favored
- Blog posts vs. books

**Effect:** Strong length normalization

### Lower b (e.g., b = 0.5):

**Use when:**

- All documents are similar length
- Length shouldn't matter much
- Academic papers (all ~8 pages)

**Effect:** Weak length normalization

## Key Takeaways

**BM25 is smarter than TF-IDF because:**

1. **Diminishing Returns** 

   - The 2nd occurrence helps a lot
   - The 100th occurrence barely helps
   - Prevents keyword stuffing naturally

2. **Length Normalization** 

   - Short, focused docs get a bonus
   - Long, rambling docs get penalized
   - Adjustable with parameter b

3. **Tunable** 

   - k1 controls term frequency importance
   - b controls length normalization
   - Customize for your use case!

4. **More Realistic** 

   - Mimics human relevance judgments
   - Used by Elasticsearch, Lucene, Solr
   - Industry standard for good reason!

<br>